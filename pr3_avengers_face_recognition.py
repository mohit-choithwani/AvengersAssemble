# -*- coding: utf-8 -*-
"""Pr3 Avengers Face recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1csuQSN-aHgd7kUmsI6upjgifU86tQDtC

Importing all the required libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import cv2
import matplotlib
from matplotlib import pyplot as plt
# %matplotlib inline

#visualize the data
img = cv2.imread('/content/drive/MyDrive/Projects/AvengersAssemble/AvengesAssemble/dr_strange/Doctor Strange.jpg')
print(img.shape)
plt.imshow(img)

#Transform this image into gray image
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
print(gray.shape)
plt.imshow(gray, cmap='gray')

"""#Open CV's Haar Cascade feature to detect faces"""

face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/Projects/Face_Recognition/haarcascades/haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/Projects/Face_Recognition/haarcascades/haarcascade_eye.xml')

#This will return the cordinates of the rectangle, where the feature detects faces
# x-cordinate, y-cordinate, width, height
faces = face_cascade.detectMultiScale(gray, 1.3, 5)
faces

#lets draw a rectangle on the face
x, y, w, h = faces[0]

face_img = cv2.rectangle(img, (x, y), (x+w, y+h), (255,0,0), 2)
plt.imshow(face_img)

#Need to find Region of Interest and detect eyes and draw rectangle on eyes

cv2.destroyAllWindows()
for (x, y, w, h) in faces:
  face_img = cv2.rectangle(img, (x, y), (x+w, y+h), (255,0,0), 2)
  roi_gray = gray[y:y+h, x:x+w]
  roi_color = face_img[y:y+h, x:x+w]
  eyes = eye_cascade.detectMultiScale(roi_gray)
  for (ex, ey, ew, eh) in eyes:
    cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)

plt.figure()
plt.imshow(face_img, cmap='gray')
plt.show()

#This will be our region of interest
plt.imshow(roi_color, cmap='gray')

#function that takes img path and returns the cropped images

def get_cropped_img(faces):
  cv2.destroyAllWindows()
  gray = cv2.cvtColor(faces, cv2.COLOR_BGR2GRAY)
  faces = face_cascade.detectMultiScale(gray, 1.3, 5)
  for (x, y, w, h) in faces:
    face_img = cv2.rectangle(img, (x, y), (x+w, y+h), (255,0,0), 2)
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = face_img[y:y+h, x:x+w]
    eyes = eye_cascade.detectMultiScale(roi_gray)
    for (ex, ey, ew, eh) in eyes:
      cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)

  return roi_gray

import os

def create_cropped_img(path):
  for files in os.listdir(path):
    counter = 0
    #for imgs in os.listdir(files):
    cropped_img = get_cropped_img(files)
    filename = 'cropped_image.jpg'
    counter = counter + 1
    cv2.imwrite(filename, cropped_img)

## This method will return the cropped image if both the eyes are detected
def get_cropped_images_with_2_eyes(image_path):
  img = cv2.imread(image_path)
  try:
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    for (x, y, w, h) in faces:
      roi_gray = gray[y:y+h, x:x+w]
      roi_color = img[y:y+h, x:x+w]
      eyes = eye_cascade.detectMultiScale(roi_gray)
      if len(eyes) >= 2:
        return roi_color
  except Exception as e:
    print(e)

path = '/content/drive/MyDrive/Projects/AvengersAssemble/AvengesAssemble/dr_strange/Benedict Cumberbatch Meets His.jpg'
original_img = cv2.imread(path)
plt.imshow(original_img)

cropped = get_cropped_images_with_2_eyes(path)
plt.imshow(cropped)

#Find some images where eyes are not visible, there our method doesn't detect face and doesn't return anything

#Path where the images directory is located and path where to save cropped images
path_to_data = "/content/drive/MyDrive/Projects/AvengersAssemble/AvengesAssemble"
path_to_cr_data = "/content/drive/MyDrive/Projects/AvengersAssemble/AvengesAssemble/cropped/"

import os

#Store paths of all the directories inside the main directory. In our case it will add the path of five subdirectories
img_dirs = []
for entry in os.scandir(path_to_data):
    if entry.is_dir():
        img_dirs.append(entry.path)
print(img_dirs)

#Create a new directory inside the main directory
import shutil
if os.path.exists(path_to_cr_data):
     shutil.rmtree(path_to_cr_data)
os.mkdir(path_to_cr_data)

#Here we call our method (get_cropped_images_with_2_eyes) on every image inside the each directory which will return cropped faces 
#i.e our region of interest. We will also rename every cropped image in this format character_image_number.
cropped_image_dirs = []
celebrity_file_names_dict = {}
for img_dir in img_dirs:
    count = 1
    celebrity_name = img_dir.split('/')[-1]
    celebrity_file_names_dict[celebrity_name] = []
    for entry in os.scandir(img_dir):
        roi_color = get_cropped_images_with_2_eyes(entry.path)
        if roi_color is not None:
            cropped_folder = path_to_cr_data + celebrity_name
            if not os.path.exists(cropped_folder):
                os.makedirs(cropped_folder)
                cropped_image_dirs.append(cropped_folder)
                print("Generating cropped images in folder: ",cropped_folder)
            cropped_file_name = celebrity_name + str(count) + ".png"
            cropped_file_path = cropped_folder + "/" + cropped_file_name
            cv2.imwrite(cropped_file_path, roi_color)
            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)
            count += 1

cropped_image_dirs

#Let's create a dictionary that will store all the characters name as it's key and path of their respective images as the value
celebrity_file_names_dict = {}
for img_dir in cropped_image_dirs:
    celebrity_name = img_dir.split('/')[-1]
    file_list = []
    for entry in os.scandir(img_dir):
        file_list.append(entry.path)
    celebrity_file_names_dict[celebrity_name] = file_list
celebrity_file_names_dict

#We will represent every charactername with an Integer that will help us in training and testing
class_dict = {}
count = 0
for celebrity_name in celebrity_file_names_dict.keys():
    class_dict[celebrity_name] = count
    count = count + 1
class_dict

"""#Wavelet Transfor"""

import numpy as np
import pywt
import cv2    

def w2d(img, mode='haar', level=1):
    imArray = img
    #Datatype conversions
    #convert to grayscale
    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )
    #convert to float
    imArray =  np.float32(imArray)   
    imArray /= 255;
    # compute coefficients 
    coeffs=pywt.wavedec2(imArray, mode, level=level)

    #Process Coefficients
    coeffs_H=list(coeffs)  
    coeffs_H[0] *= 0;  

    # reconstruction
    imArray_H=pywt.waverec2(coeffs_H, mode);
    imArray_H *= 255;
    imArray_H =  np.uint8(imArray_H)

    return imArray_H

X, y = [], []
for celebrity_name, training_files in celebrity_file_names_dict.items():
    for training_image in training_files:
      try:
        img = cv2.imread(training_image)
        scalled_raw_img = cv2.resize(img, (32, 32))
        img_har = w2d(img,'db1',5)
        scalled_img_har = cv2.resize(img_har, (32, 32))
        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))
        X.append(combined_img)
        y.append(class_dict[celebrity_name]) 
      except Exception as e:
        print(str(e))

len(X[0])

X = np.array(X).reshape(len(X),4096).astype(float)
X.shape

"""Model Training"""

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10, probability=True))])
pipe.fit(X_train, y_train)
pipe.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, pipe.predict(X_test))
cm

import seaborn as sn
plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')

!pip install joblib
import joblib 
# Save the model as a pickle in a file 
joblib.dump(pipe, 'saved_model.pkl')

from sklearn import svm
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV

model_params = {
    'svm': {
        'model': svm.SVC(gamma='auto',probability=True),
        'params' : {
            'svc__C': [1,10,100,1000],
            'svc__kernel': ['rbf','linear']
        }  
    },
    'random_forest': {
        'model': RandomForestClassifier(),
        'params' : {
            'randomforestclassifier__n_estimators': [1,5,10]
        }
    },
    'logistic_regression' : {
        'model': LogisticRegression(solver='liblinear',multi_class='auto'),
        'params': {
            'logisticregression__C': [1,5,10]
        }
    }
}

scores = []
best_estimators = {}
import pandas as pd
for algo, mp in model_params.items():
    pipe = make_pipeline(StandardScaler(), mp['model'])
    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)
    clf.fit(X_train, y_train)
    scores.append({
        'model': algo,
        'best_score': clf.best_score_,
        'best_params': clf.best_params_
    })
    best_estimators[algo] = clf.best_estimator_
    
df = pd.DataFrame(scores,columns=['model','best_score','best_params'])
df

best_estimators['svm'].score(X_test,y_test)

best_estimators['random_forest'].score(X_test,y_test)

best_estimators['logistic_regression'].score(X_test,y_test)

import json
with open("class_dictionary.json","w") as f:
    f.write(json.dumps(class_dict))

"""# New Approach PCA and SVM"""

import numpy as np
import pandas as pd
import torch
import torchvision
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.decomposition import PCA as RandomizedPCA
from sklearn.svm import SVC

dataset = torchvision.datasets.ImageFolder('/content/drive/MyDrive/Projects/Face_Recognition/images_dataset')

dataset[100]

data =  torchvision.datasets.ImageFolder('/content/drive/MyDrive/Projects/Face_Recognition/images_dataset/cropped')

for img, label in data:
  print(label)
  plt.imshow(img, cmap='gray')
  print(len(data))
  break

target = []
img_data = []

for img, label in data:
  target.append(label)
  img = np.asarray(img)
  img_data.append(img)

len(img_data)

#Converting list into numpy array
img_data = np.asarray(img_data)
target = np.asarray(target)

x_train, x_test, y_train, y_test = train_test_split(img_data, target, test_size=0.25, random_state=42)

y_test.shape

n_components = 20

import pandas as pd

data = [['apple', 209, 51],
        ['orange', 190, 31],
        ['apple', 239, 57],
        ['apple', 211, 50],
        ['orange', 178, 41],
        ['orange', 179, 39],
        ['apple', 229, 53],
        ['orange', 188, 41],
        ['apple', 209, 51],
        ['orange', 169, 21],
        ['apple', 202, 52],
        ['orange', 170, 37],
        ['apple', 249, 59],
        ['apple', 211, 51],
        ['orange', 188, 39],
        ['orange', 199, 49],
        ['apple', 210, 53],
        ['orange', 158, 43],
        ['apple', 290, 61],
        ['orange', 179, 27]
        ]

df = pd.DataFrame(data, columns=['target', 'weight', 'size'])

df.head()

"""Spliting the dataset into training and testing"""

from sklearn.model_selection import train_test_split

train_set, test_set = train_test_split(df, test_size=0.2, random_state=0)

"""Classify target and independent columns"""

x_train = train_set.iloc[:,1:3].values
x_test = test_set.iloc[:,1:3].values
y_train = train_set.iloc[:,0].values
y_test = test_set.iloc[:,0].values

print(x_train, x_test, y_train, y_test)

"""Initializing Support vector machine and fitting the data"""

from sklearn.svm import SVC

classifier = SVC(kernel='rbf', random_state=1)
classifier.fit(x_train,y_train)

#Predicting the classes
y_pred = classifier.predict(x_test)

test_set["Prediction"] = y_pred

test_set

"""Calculating the accuracy of prediction"""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,y_pred)
accuracy = float(cm.diagonal().sum())/len(y_test)
print("\nAccuracy Of SVM For The Given Dataset : ", accuracy)

"""Visualizing the classifier"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_train = le.fit_transform(y_train)
y_train

from sklearn.svm import SVC
classifier = SVC(kernel='rbf', random_state = 1)
classifier.fit(x_train,y_train)

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap

plt.figure(figsize = (7,7))
X_set, y_set = x_train, y_train
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01), np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('black', 'white')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
  plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'orange'))(i), label = j)
plt.title('Apples Vs Oranges')
plt.xlabel('Weight In Grams')
plt.ylabel('Size in cm')
plt.legend()
plt.show()